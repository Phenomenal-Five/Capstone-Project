{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, zero_one_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('../datasets/kddcup.data_10_percent.gz', header=None)\n",
    "# Raw Data Backup\n",
    "raw_data_backup = raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditions start to be in categories\n",
    "DOS = (raw_data[41] == 'back.') | (raw_data[41] == 'land.') | (raw_data[41] == 'neptune.') | (raw_data[41] == 'pod.') | (raw_data[41] == 'smurf.') | (raw_data[41] == 'teardrop.')\n",
    "U2R = (raw_data[41] == 'buffer_overflow.') | (raw_data[41] == 'loadmodule.') | (raw_data[41] == 'perl.') | (raw_data[41] == 'rootkit.')\n",
    "R2L = (raw_data[41] == 'ftp_write.') | (raw_data[41] == 'guess_passwd.') | (raw_data[41] == 'imap.') | (raw_data[41] == 'multihop.') | (raw_data[41] == 'phf.') | (raw_data[41] == 'spy.') | (raw_data[41] == 'warezclient.') | (raw_data[41] == 'warezmaster.')\n",
    "probe = (raw_data[41] == 'satan.') | (raw_data[41] == 'ipsweep.') | (raw_data[41] == 'portsweep.') | (raw_data[41] == 'nmap.')\n",
    "# Conditions end\n",
    "\n",
    "raw_data[42] = np.where(DOS, 'dos', np.where(U2R, 'u2r', np.where(R2L, 'r2l', np.where(probe, 'probe', raw_data[41]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data[43] = np.where((raw_data[41] == 'normal.'), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropped Column [6, 8, 14, 18, 19, 20] for Feature Selection\n",
    "raw_data.drop([6, 8, 14, 18, 19, 20], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal.</td>\n",
       "      <td>normal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1     2   3    4     5   7   9   10  11 ...   34    35   36   37   38  \\\n",
       "0   0  tcp  http  SF  181  5450   0   0   0   1 ...  0.0  0.11  0.0  0.0  0.0   \n",
       "1   0  tcp  http  SF  239   486   0   0   0   1 ...  0.0  0.05  0.0  0.0  0.0   \n",
       "2   0  tcp  http  SF  235  1337   0   0   0   1 ...  0.0  0.03  0.0  0.0  0.0   \n",
       "3   0  tcp  http  SF  219  1337   0   0   0   1 ...  0.0  0.03  0.0  0.0  0.0   \n",
       "4   0  tcp  http  SF  217  2032   0   0   0   1 ...  0.0  0.02  0.0  0.0  0.0   \n",
       "\n",
       "    39   40       41       42  43  \n",
       "0  0.0  0.0  normal.  normal.   0  \n",
       "1  0.0  0.0  normal.  normal.   0  \n",
       "2  0.0  0.0  normal.  normal.   0  \n",
       "3  0.0  0.0  normal.  normal.   0  \n",
       "4  0.0  0.0  normal.  normal.   0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize columns: \"protocol\", \"service\", \"flag\", \"attack_type\"\n",
    "raw_data[1], protocols= pd.factorize(raw_data[1])\n",
    "raw_data[2], services = pd.factorize(raw_data[2])\n",
    "raw_data[3], flags    = pd.factorize(raw_data[3])\n",
    "raw_data[41], attacks = pd.factorize(raw_data[41])\n",
    "raw_data[42], attacks_cat = pd.factorize(raw_data[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = raw_data.iloc[:,:raw_data.shape[1]-3]\n",
    "labels = raw_data.iloc[:,raw_data.shape[1]-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# convert them into numpy arrays\n",
    "#features= numpy.array(features)\n",
    "#labels= numpy.array(labels).ravel() # this becomes an 'horizontal' array\n",
    "labels = labels.values.ravel() # this becomes a 'horizontal' array\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train, y_train: (395216, 35) (395216,)\n",
      "X_test, y_test: (98805, 35) (98805,)\n"
     ]
    }
   ],
   "source": [
    "# Separate data in train set and test set\n",
    "df = pd.DataFrame(features)\n",
    "# create training and testing vars\n",
    "# Note: train_size + test_size < 1.0 means we are subsampling\n",
    "# Use small numbers for slow classifiers, as KNN, Radius, SVC,...\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, labels, train_size=0.8, test_size=0.2)\n",
    "print(\"X_train, y_train:\", X_train.shape, y_train.shape)\n",
    "print(\"X_test, y_test:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>403850</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424171</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277486</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345312</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458504</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1804</td>\n",
       "      <td>330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1   2   3     4    5   7   9   10  11 ...    34    35    36   37  \\\n",
       "403850   0   2   9   0   520    0   0   0   0   0 ...  0.00  1.00  0.00  0.0   \n",
       "424171   0   2   9   0   520    0   0   0   0   0 ...  0.00  1.00  0.00  0.0   \n",
       "277486   0   2   9   0  1032    0   0   0   0   0 ...  0.00  1.00  0.00  0.0   \n",
       "345312   0   1   3   0    32   48   0   0   0   0 ...  0.01  0.00  0.00  0.0   \n",
       "458504   1   0   1   0  1804  330   0   0   0   1 ...  0.03  0.01  0.02  0.0   \n",
       "\n",
       "         38   39   40  41  42  43  \n",
       "403850  0.0  0.0  0.0   5   2   1  \n",
       "424171  0.0  0.0  0.0   5   2   1  \n",
       "277486  0.0  0.0  0.0   5   2   1  \n",
       "345312  0.0  0.0  0.0   0   0   0  \n",
       "458504  0.0  0.0  0.0   0   0   0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indexes = X_train.index.values\n",
    "Training_Dataset = raw_data.loc[train_indexes,:]\n",
    "Training_Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398609</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339581</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>1481</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460294</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39666</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1960</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0   1   2   3     4     5   7   9   10  11 ...    34    35    36   37  \\\n",
       "398609   0   2   9   0   520     0   0   0   0   0 ...  0.00  1.00  0.00  0.0   \n",
       "339581   0   2   9   0  1032     0   0   0   0   0 ...  0.00  1.00  0.00  0.0   \n",
       "302      0   0   0   0   310  1481   0   0   0   1 ...  0.00  0.00  0.00  0.0   \n",
       "460294   0   0  11   2     0     0   0   0   0   0 ...  0.06  0.00  0.00  0.0   \n",
       "39666    2   0   1   0  1960   400   0   0   0   1 ...  0.02  0.01  0.02  0.0   \n",
       "\n",
       "         38   39   40  41  42  43  \n",
       "398609  0.0  0.0  0.0   5   2   1  \n",
       "339581  0.0  0.0  0.0   5   2   1  \n",
       "302     0.0  0.0  0.0   0   0   0  \n",
       "460294  0.0  1.0  1.0   4   2   1  \n",
       "39666   0.0  0.0  0.0   0   0   0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indexes = X_test.index.values\n",
    "Testing_Dataset = raw_data.loc[test_indexes,:]\n",
    "Testing_Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_Training_Sub_Dataset = Training_Dataset.loc[Training_Dataset[42] == 0] # Normal\n",
    "Attack_Training_Sub_Dataset = Training_Dataset.loc[Training_Dataset[43] == 1] # Attack\n",
    "U2R_Training_Sub_Dataset    = Training_Dataset.loc[Training_Dataset[42] == 1] # u2r\n",
    "DOS_Training_Sub_Dataset    = Training_Dataset.loc[Training_Dataset[42] == 2] # dos\n",
    "R2L_Training_Sub_Dataset    = Training_Dataset.loc[Training_Dataset[42] == 3] # r2l\n",
    "Probe_Training_Sub_Dataset  = Training_Dataset.loc[Training_Dataset[42] == 4] # probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(raw_data, feature_column):\n",
    "    X_train = raw_data.iloc[:,:raw_data.shape[1]-3]\n",
    "    y_train = raw_data[feature_column]\n",
    "    \n",
    "    # convert them into numpy arrays\n",
    "    #features= numpy.array(features)\n",
    "    #labels= numpy.array(labels).ravel() # this becomes an 'horizontal' array\n",
    "    y_train = y_train.values.ravel() # this becomes a 'horizontal' array\n",
    "    \n",
    "    df = pd.DataFrame(X_train)\n",
    "    \n",
    "    # Training, choose model by commenting/uncommenting clf=\n",
    "    print(\"Training model\")\n",
    "    # Random Forest Classifier\n",
    "\n",
    "    rfc = RandomForestClassifier(n_jobs=-1, random_state=3, n_estimators=102)\n",
    "    \n",
    "    model = rfc.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Score: \", model.score(X_train, y_train))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X(dataset):\n",
    "    X_test = dataset.iloc[:,:raw_data.shape[1]-3]\n",
    "    return X_test\n",
    "\n",
    "\n",
    "def get_y(dataset, feature_column):\n",
    "    y_test = dataset[feature_column]\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def test_model(model, X_test, y_test, target_names):    \n",
    "    print(\"X_test, y_test:\", X_test.shape, y_test.shape)\n",
    "    \n",
    "    # Predicting\n",
    "    print(\"Predicting\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_test = np.vectorize(target_names.get)(y_test)\n",
    "    y_pred = np.vectorize(target_names.get)(y_pred)\n",
    "    \n",
    "    # print('Target Values are: ')\n",
    "    # print(pd.DataFrame(np.array(target_names)))\n",
    "    # print(target_names)\n",
    "    # Making the Confusion Matrix\n",
    "    print(\"=================================== Confusion Matrix ==================================\")\n",
    "    pd_cm = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "    error = zero_one_loss(y_test, y_pred)\n",
    "    print(pd_cm)\n",
    "    \n",
    "    print(\"============================= Printing Classification Report ==========================\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_by_attack_name(model, X_test_category, y_pred_category, cat_id):\n",
    "#     attack_name_model_test = X_test\n",
    "    # Concating the X_test and y_test\n",
    "    X_test_category.loc[:,42] = y_pred_category\n",
    "    Test_Rows = X_test_category.loc[X_test_category[42] == cat_id] # Attack Name\n",
    "\n",
    "    # X_test_attack_category = get_X(attack_to_category)\n",
    "    X_test = get_X(Test_Rows)\n",
    "    # y_test_attack_category = get_y(attack_to_category, 43)\n",
    "\n",
    "    model_pred = get_prediction(model, X_test)\n",
    "\n",
    "    test_indexes = Test_Rows.index.values\n",
    "    Testing_Sub_Dataset = Testing_Dataset.loc[test_indexes,:]\n",
    "\n",
    "    y_test = get_y(Testing_Sub_Dataset, 41)\n",
    "    test_model(model, X_test, y_test, target_names_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(model, X_test):\n",
    "    print(\"X_test:\", X_test.shape)\n",
    "    \n",
    "    # Predicting\n",
    "    print(\"Predicting\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"================================ Prediction Probability ===============================\")\n",
    "    print(model.predict_proba(X_test))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the target names for confusion matrix   \n",
    "target_names_root   = dict(zip([0, 1], ['normal', 'attack']))\n",
    "target_names_cat    = dict(zip(np.unique(raw_data[42].values.ravel()), attacks_cat))\n",
    "target_names_attack = dict(zip(np.unique(labels), attacks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "Score:  0.9999949394761346\n"
     ]
    }
   ],
   "source": [
    "root_model = make_model(Training_Dataset, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n",
      "Score:  1.0\n",
      "Training model\n",
      "Score:  1.0\n",
      "Training model\n",
      "Score:  1.0\n",
      "Training model\n",
      "Score:  1.0\n",
      "Training model\n",
      "Score:  0.9996953077391835\n"
     ]
    }
   ],
   "source": [
    "# Making Model\n",
    "attack_category_model = make_model(Attack_Training_Sub_Dataset, 42)\n",
    "u2r_model    = make_model(U2R_Training_Sub_Dataset, 41)\n",
    "dos_model    = make_model(DOS_Training_Sub_Dataset, 41)\n",
    "r2l_model    = make_model(R2L_Training_Sub_Dataset, 41)\n",
    "probe_model  = make_model(Probe_Training_Sub_Dataset, 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_root_model = get_X(Testing_Dataset)\n",
    "y_test_root_model = get_y(Testing_Dataset, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_our_model(X_test, y_test):\n",
    "    X_test_root_model = X_test\n",
    "    y_test_root_model = y_test\n",
    "    # Test Root Model\n",
    "    print(\"======================================================================================\")\n",
    "    print(\"================================ Root Model Output ===================================\")\n",
    "    print(\"======================================================================================\")\n",
    "    test_model(root_model, X_test_root_model, y_test_root_model, target_names_root)\n",
    "    root_model_pred = get_prediction(root_model, X_test_root_model)\n",
    "    category_model_test = X_test_root_model.copy()\n",
    "    # Concating the X_test and y_test\n",
    "    category_model_test.loc[:,43] = root_model_pred\n",
    "    attack_to_category = category_model_test.loc[category_model_test[43] == 1] # Attack\n",
    "    attack_to_category.head()\n",
    "    \n",
    "    # Test Category Model\n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(\"======================================================================================\")\n",
    "    print(\"================================ Category Model Output ===============================\")\n",
    "    print(\"======================================================================================\")\n",
    "    Attack_Training_Sub_Dataset = Training_Dataset.loc[Training_Dataset[43] == 1] # Attack\n",
    "    X_test_attack_category = get_X(attack_to_category)\n",
    "    attack_category_model_pred = get_prediction(attack_category_model, X_test_attack_category)\n",
    "    \n",
    "    attack_category_test_indexes = attack_to_category.index.values\n",
    "    Attack_Testing_Sub_Dataset = Testing_Dataset.loc[attack_category_test_indexes,:]\n",
    "\n",
    "    y_test_attack_category = get_y(Attack_Testing_Sub_Dataset, 42)\n",
    "    test_model(attack_category_model, X_test_attack_category, y_test_attack_category, target_names_cat)\n",
    "    \n",
    "    # U2R Model Testing\n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(\"======================================================================================\")\n",
    "    print(\"=================================== U2R Model Output =================================\")\n",
    "    print(\"======================================================================================\")\n",
    "    test_by_attack_name(u2r_model, X_test_attack_category, attack_category_model_pred, 1)\n",
    "    # DOS Model Testing\n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(\"======================================================================================\")\n",
    "    print(\"=================================== DOS Model Output =================================\")\n",
    "    print(\"======================================================================================\")\n",
    "    test_by_attack_name(dos_model, X_test_attack_category, attack_category_model_pred, 2)\n",
    "    # R2L Model Testing\n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(\"======================================================================================\")\n",
    "    print(\"=================================== R2L Model Output =================================\")\n",
    "    print(\"======================================================================================\")\n",
    "    test_by_attack_name(r2l_model, X_test_attack_category, attack_category_model_pred, 3)\n",
    "    # Probe Model Testing\n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(\"======================================================================================\")\n",
    "    print(\"=================================== Probe Model Output ===============================\")\n",
    "    print(\"======================================================================================\")\n",
    "    test_by_attack_name(probe_model, X_test_attack_category, attack_category_model_pred, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================\n",
      "================================ Root Model Output ===================================\n",
      "======================================================================================\n",
      "X_test, y_test: (98805, 35) (98805,)\n",
      "Predicting\n",
      "=================================== Confusion Matrix ==================================\n",
      "Predicted  attack  normal\n",
      "Actual                   \n",
      "attack      79403       7\n",
      "normal          2   19393\n",
      "============================= Printing Classification Report ==========================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      attack       1.00      1.00      1.00     79410\n",
      "      normal       1.00      1.00      1.00     19395\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     98805\n",
      "   macro avg       1.00      1.00      1.00     98805\n",
      "weighted avg       1.00      1.00      1.00     98805\n",
      "\n",
      "X_test: (98805, 35)\n",
      "Predicting\n",
      "================================ Prediction Probability ===============================\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "================================ Category Model Output ===============================\n",
      "======================================================================================\n",
      "X_test: (79405, 35)\n",
      "Predicting\n",
      "================================ Prediction Probability ===============================\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n",
      "X_test, y_test: (79405, 35) (79405,)\n",
      "Predicting\n",
      "=================================== Confusion Matrix ==================================\n",
      "Predicted    dos  probe  r2l  u2r\n",
      "Actual                           \n",
      "dos        78355      0    0    0\n",
      "normal.        0      1    1    0\n",
      "probe          0    824    0    0\n",
      "r2l            0      0  216    0\n",
      "u2r            0      0    0    8\n",
      "============================= Printing Classification Report ==========================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dos       1.00      1.00      1.00     78355\n",
      "     normal.       0.00      0.00      0.00         2\n",
      "       probe       1.00      1.00      1.00       824\n",
      "         r2l       1.00      1.00      1.00       216\n",
      "         u2r       1.00      1.00      1.00         8\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     79405\n",
      "   macro avg       0.80      0.80      0.80     79405\n",
      "weighted avg       1.00      1.00      1.00     79405\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "=================================== U2R Model Output =================================\n",
      "======================================================================================\n",
      "X_test: (8, 35)\n",
      "Predicting\n",
      "================================ Prediction Probability ===============================\n",
      "[[0.70588235 0.08823529 0.         0.20588235]\n",
      " [0.94117647 0.03921569 0.00980392 0.00980392]\n",
      " [0.78431373 0.09803922 0.         0.11764706]\n",
      " [0.57843137 0.33333333 0.00980392 0.07843137]\n",
      " [0.59803922 0.35294118 0.00980392 0.03921569]\n",
      " [0.99019608 0.         0.         0.00980392]\n",
      " [0.56862745 0.25490196 0.10784314 0.06862745]\n",
      " [0.78431373 0.15686275 0.         0.05882353]]\n",
      "X_test, y_test: (8, 35) (8,)\n",
      "Predicting\n",
      "=================================== Confusion Matrix ==================================\n",
      "Predicted         buffer_overflow.\n",
      "Actual                            \n",
      "buffer_overflow.                 7\n",
      "loadmodule.                      1\n",
      "============================= Printing Classification Report ==========================\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "buffer_overflow.       0.88      1.00      0.93         7\n",
      "     loadmodule.       0.00      0.00      0.00         1\n",
      "\n",
      "       micro avg       0.88      0.88      0.88         8\n",
      "       macro avg       0.44      0.50      0.47         8\n",
      "    weighted avg       0.77      0.88      0.82         8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "=================================== DOS Model Output =================================\n",
      "======================================================================================\n",
      "X_test: (78355, 35)\n",
      "Predicting\n",
      "================================ Prediction Probability ===============================\n",
      "[[0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]]\n",
      "X_test, y_test: (78355, 35) (78355,)\n",
      "Predicting\n",
      "=================================== Confusion Matrix ==================================\n",
      "Predicted  back.  land.  neptune.  pod.  smurf.  teardrop.\n",
      "Actual                                                    \n",
      "back.        422      0         0     0       0          0\n",
      "land.          0      5         0     0       0          0\n",
      "neptune.       0      0     21352     0       0          0\n",
      "pod.           0      0         0    53       0          0\n",
      "smurf.         0      0         0     0   56310          0\n",
      "teardrop.      0      0         0     0       0        213\n",
      "============================= Printing Classification Report ==========================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       back.       1.00      1.00      1.00       422\n",
      "       land.       1.00      1.00      1.00         5\n",
      "    neptune.       1.00      1.00      1.00     21352\n",
      "        pod.       1.00      1.00      1.00        53\n",
      "      smurf.       1.00      1.00      1.00     56310\n",
      "   teardrop.       1.00      1.00      1.00       213\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     78355\n",
      "   macro avg       1.00      1.00      1.00     78355\n",
      "weighted avg       1.00      1.00      1.00     78355\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "=================================== R2L Model Output =================================\n",
      "======================================================================================\n",
      "X_test: (217, 35)\n",
      "Predicting\n",
      "================================ Prediction Probability ===============================\n",
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "X_test, y_test: (217, 35) (217,)\n",
      "Predicting\n",
      "=================================== Confusion Matrix ==================================\n",
      "Predicted      guess_passwd.  imap.  warezclient.  warezmaster.\n",
      "Actual                                                         \n",
      "guess_passwd.             10      0             0             0\n",
      "imap.                      0      1             0             0\n",
      "normal.                    0      0             0             1\n",
      "warezclient.               0      0           204             0\n",
      "warezmaster.               0      0             0             1\n",
      "============================= Printing Classification Report ==========================\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "guess_passwd.       1.00      1.00      1.00        10\n",
      "        imap.       1.00      1.00      1.00         1\n",
      "      normal.       0.00      0.00      0.00         1\n",
      " warezclient.       1.00      1.00      1.00       204\n",
      " warezmaster.       0.50      1.00      0.67         1\n",
      "\n",
      "    micro avg       1.00      1.00      1.00       217\n",
      "    macro avg       0.70      0.80      0.73       217\n",
      " weighted avg       0.99      1.00      0.99       217\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "======================================================================================\n",
      "=================================== Probe Model Output ===============================\n",
      "======================================================================================\n",
      "X_test: (825, 35)\n",
      "Predicting\n",
      "================================ Prediction Probability ===============================\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "X_test, y_test: (825, 35) (825,)\n",
      "Predicting\n",
      "=================================== Confusion Matrix ==================================\n",
      "Predicted   ipsweep.  nmap.  portsweep.  satan.\n",
      "Actual                                         \n",
      "ipsweep.         230      0           0       0\n",
      "nmap.              1     40           0       0\n",
      "normal.            0      0           0       1\n",
      "portsweep.         0      0         218       0\n",
      "satan.             1      0           0     334\n",
      "============================= Printing Classification Report ==========================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    ipsweep.       0.99      1.00      1.00       230\n",
      "       nmap.       1.00      0.98      0.99        41\n",
      "     normal.       0.00      0.00      0.00         1\n",
      "  portsweep.       1.00      1.00      1.00       218\n",
      "      satan.       1.00      1.00      1.00       335\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       825\n",
      "   macro avg       0.80      0.79      0.80       825\n",
      "weighted avg       1.00      1.00      1.00       825\n",
      "\n",
      "Execution Time:  50.6905529 Sec\n",
      "Wall time: 6.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_our_model(X_test_root_model, y_test_root_model)\n",
    "print('Execution Time: ', timeit.default_timer() - start_time, 'Sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_by_attack_name(model, X_test_category, y_pred_category, cat_id):\n",
    "#     attack_name_model_test = X_test\n",
    "    # Concating the X_test and y_test\n",
    "    X_test_category.loc[:,42] = y_pred_category\n",
    "    Test_Rows = X_test_category.loc[X_test_category[42] == cat_id] # Attack Name\n",
    "\n",
    "    # X_test_attack_category = get_X(attack_to_category)\n",
    "    X_test = get_X(Test_Rows)\n",
    "    # y_test_attack_category = get_y(attack_to_category, 43)\n",
    "\n",
    "    model_pred = get_prediction(model, X_test)\n",
    "    return model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_instance(X_test):\n",
    "    X_test_root_model = X_test\n",
    "    # Predict Root Model\n",
    "    root_model_pred = get_prediction(root_model, X_test_root_model)\n",
    "    print(root_model_pred)\n",
    "    \n",
    "    # For Category Nodes\n",
    "    category_model_test = X_test_root_model.copy()\n",
    "    # Concating the X_test and y_test\n",
    "    category_model_test.loc[:,43] = root_model_pred\n",
    "    attack_to_category = category_model_test.loc[category_model_test[43] == 1] # Attack\n",
    "    \n",
    "    \n",
    "    # Predict Category Model\n",
    "    if(attack_to_category.shape[0]>0):\n",
    "        X_test_attack_category = get_X(attack_to_category)\n",
    "        attack_category_model_pred = get_prediction(attack_category_model, X_test_attack_category)\n",
    "        print(attack_category_model_pred)\n",
    "    \n",
    "    # For Attack Nodes\n",
    "    attack_model_test = X_test_attack_category.copy()\n",
    "    # Concating the X_test and y_test\n",
    "    attack_model_test.loc[:,42] = attack_category_model_pred\n",
    "    category_to_u2r = attack_model_test.loc[attack_model_test[42] == 1] # U2R\n",
    "    category_to_dos = attack_model_test.loc[attack_model_test[42] == 2] # DOS\n",
    "    category_to_r2l = attack_model_test.loc[attack_model_test[42] == 3] # R2L\n",
    "    category_to_probe = attack_model_test.loc[attack_model_test[42] == 4] # Probe\n",
    "    \n",
    "    # U2R Model Predict\n",
    "    if(category_to_u2r.shape[0]>0):\n",
    "        attack_names = get_prediction(u2r_model, get_X(category_to_u2r))\n",
    "        print(attack_names)\n",
    "        \n",
    "    # DOS Model Predict\n",
    "    if(category_to_dos.shape[0]>0):\n",
    "        attack_names = get_prediction(dos_model, get_X(category_to_dos))\n",
    "        print(attack_names)\n",
    "        \n",
    "    # R2L Model Predict\n",
    "    if(category_to_r2l.shape[0]>0):\n",
    "        attack_names = get_prediction(r2l_model, get_X(category_to_r2l))\n",
    "        print(attack_names)\n",
    "        \n",
    "    # Probe Model Predict\n",
    "    if(category_to_probe.shape[0]>0):\n",
    "        attack_names = get_prediction(probe_model, get_X(category_to_probe))\n",
    "        print(attack_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_value_count = pd.DataFrame(np.vectorize(target_names_attack.get)(Training_Dataset[41]))[0].value_counts()\n",
    "# train_value_count.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_value_count = pd.DataFrame(np.vectorize(target_names_attack.get)(Testing_Dataset[41]))[0].value_counts()\n",
    "# test_value_count.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Dataset.to_csv('output/train_dataset.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing_Dataset.to_csv('output/test_dataset.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Value Shape:  (23,)\n",
      "Test  Value Shape:  (19,)\n"
     ]
    }
   ],
   "source": [
    "print('Train Value Shape: ', train_value_count.shape)\n",
    "print('Test  Value Shape: ', test_value_count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex(levels=[['Train', 'Test'], [0]],\n",
       "           labels=[[0, 1], [0, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([train_value_count.to_frame(), test_value_count.to_frame()], \n",
    "                   axis='columns', keys=['Train', 'Test']).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow18_col1 {\n",
       "            background-color:  red;\n",
       "        }    #T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow20_col1 {\n",
       "            background-color:  red;\n",
       "        }    #T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow21_col1 {\n",
       "            background-color:  red;\n",
       "        }    #T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow22_col1 {\n",
       "            background-color:  red;\n",
       "        }</style>  \n",
       "<table id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3e\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >Train</th> \n",
       "        <th class=\"col_heading level0 col1\" >Test</th> \n",
       "    </tr>    <tr> \n",
       "        <th class=\"blank level1\" ></th> \n",
       "        <th class=\"col_heading level1 col0\" >0</th> \n",
       "        <th class=\"col_heading level1 col1\" >0</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row0\" class=\"row_heading level0 row0\" >smurf.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow0_col0\" class=\"data row0 col0\" >224480</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow0_col1\" class=\"data row0 col1\" >56310</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row1\" class=\"row_heading level0 row1\" >neptune.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow1_col0\" class=\"data row1 col0\" >85849</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow1_col1\" class=\"data row1 col1\" >21352</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row2\" class=\"row_heading level0 row2\" >normal.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow2_col0\" class=\"data row2 col0\" >77883</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow2_col1\" class=\"data row2 col1\" >19395</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row3\" class=\"row_heading level0 row3\" >back.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow3_col0\" class=\"data row3 col0\" >1781</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow3_col1\" class=\"data row3 col1\" >422</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row4\" class=\"row_heading level0 row4\" >satan.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow4_col0\" class=\"data row4 col0\" >1253</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow4_col1\" class=\"data row4 col1\" >336</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row5\" class=\"row_heading level0 row5\" >ipsweep.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow5_col0\" class=\"data row5 col0\" >1017</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow5_col1\" class=\"data row5 col1\" >230</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row6\" class=\"row_heading level0 row6\" >portsweep.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow6_col0\" class=\"data row6 col0\" >822</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow6_col1\" class=\"data row6 col1\" >218</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row7\" class=\"row_heading level0 row7\" >warezclient.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow7_col0\" class=\"data row7 col0\" >815</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow7_col1\" class=\"data row7 col1\" >205</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row8\" class=\"row_heading level0 row8\" >teardrop.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow8_col0\" class=\"data row8 col0\" >766</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow8_col1\" class=\"data row8 col1\" >213</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row9\" class=\"row_heading level0 row9\" >pod.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow9_col0\" class=\"data row9 col0\" >211</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow9_col1\" class=\"data row9 col1\" >53</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row10\" class=\"row_heading level0 row10\" >nmap.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow10_col0\" class=\"data row10 col0\" >190</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow10_col1\" class=\"data row10 col1\" >41</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row11\" class=\"row_heading level0 row11\" >guess_passwd.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow11_col0\" class=\"data row11 col0\" >43</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow11_col1\" class=\"data row11 col1\" >10</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row12\" class=\"row_heading level0 row12\" >buffer_overflow.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow12_col0\" class=\"data row12 col0\" >23</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow12_col1\" class=\"data row12 col1\" >7</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row13\" class=\"row_heading level0 row13\" >warezmaster.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow13_col0\" class=\"data row13 col0\" >19</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow13_col1\" class=\"data row13 col1\" >1</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row14\" class=\"row_heading level0 row14\" >land.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow14_col0\" class=\"data row14 col0\" >16</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow14_col1\" class=\"data row14 col1\" >5</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row15\" class=\"row_heading level0 row15\" >imap.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow15_col0\" class=\"data row15 col0\" >10</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow15_col1\" class=\"data row15 col1\" >2</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row16\" class=\"row_heading level0 row16\" >rootkit.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow16_col0\" class=\"data row16 col0\" >8</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow16_col1\" class=\"data row16 col1\" >2</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row17\" class=\"row_heading level0 row17\" >ftp_write.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow17_col0\" class=\"data row17 col0\" >7</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow17_col1\" class=\"data row17 col1\" >1</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row18\" class=\"row_heading level0 row18\" >multihop.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow18_col0\" class=\"data row18 col0\" >7</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow18_col1\" class=\"data row18 col1\" >nan</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row19\" class=\"row_heading level0 row19\" >loadmodule.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow19_col0\" class=\"data row19 col0\" >7</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow19_col1\" class=\"data row19 col1\" >2</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row20\" class=\"row_heading level0 row20\" >phf.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow20_col0\" class=\"data row20 col0\" >4</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow20_col1\" class=\"data row20 col1\" >nan</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row21\" class=\"row_heading level0 row21\" >perl.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow21_col0\" class=\"data row21 col0\" >3</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow21_col1\" class=\"data row21 col1\" >nan</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3elevel0_row22\" class=\"row_heading level0 row22\" >spy.</th> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow22_col0\" class=\"data row22 col0\" >2</td> \n",
       "        <td id=\"T_710eef46_fc4d_11e8_b8fc_fc15b4ffff3erow22_col1\" class=\"data row22 col1\" >nan</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15a857460b8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([train_value_count.to_frame(), test_value_count.to_frame()], \n",
    "                   axis='columns', keys=['Train', 'Test']).sort_values([('Train', 0)], ascending=False).style.highlight_null(null_color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time:  68.2332332 Sec\n"
     ]
    }
   ],
   "source": [
    "stop_time = timeit.default_timer()\n",
    "print('Execution Time: ', stop_time - start_time, 'Sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
